# Heart Failure Prediction using KNN, Naïve Bayes, Logistic Regression and Decision Trees

Data set : https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction. 

Project Domain:
We are aware of the fact that cardiovascular diseases (CVDs) are the leading cause of death worldwide, killing an estimated 17.9 million people each year, accounting for 31% of all deaths. Heart attacks and strokes account for four out of every five CVD deaths, and one-third of these deaths occur in adults under the age of 70. 
CVDs are a common cause of heart failure and we intend to predict heart disease based on the 12 attributes that we have in our dataset.
We’re going to use a dataset of 36kB from Kaggle which has 12 attributes – Age, Sex, ChestPainType (like Typical Angina, Atypical Angina, Non-Anginal Pain, Asymptomatic), RestingBP, Cholesterol, FastingBS (1 if FastingBs > 120 mg/dl, 0 otherwise), RestingECG (Normal: normal electrocardiogram, ST: having ST wave abnormality or LVH: definite left ventricular hypertrophy), MaxHR (maximum heart rate achieved between 60 and 202), ExerciseAngina (Y person has exercise induced angina, N otherwise), Oldpeak (numeric value), ST_Slope (Up, Flat, Down), HeartDisease (1 if heart disease present, 0 otherwise)

Learning Methods Used:
  [1] KNN
  [2] Naive Bayes
  [3] Decision Tree
  [4] Logistic Regression

Result:
The hypothesis that that we can create an efficient model by implementing various commonly used algorithms – K nearest neighbors, Naïve Bayes, Logistic Regression and Decision Treeholds true for every algorithm except KNN. We observed that our models predicted with an accuracy of 91.8% using Logistic 
Regression, 81% using Decision Tree, 89.1% using Naïve Bayes and 57.6% using KNN
